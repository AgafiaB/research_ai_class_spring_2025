{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00fb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary solution to crashing\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mysql.connector as connector\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import tqdm\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de19d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser('~')\n",
    "os.chdir(home) # b/c we will be using universal paths\n",
    "\n",
    "host = '127.0.0.1'\n",
    "user = 'root' # change to your username\n",
    "password = 'vasya1' # change to your password\n",
    "database = 'ai_proj_2025' # for the sake of sanity, we should all have this as the db name \n",
    "\n",
    "try:\n",
    "    conn = connector.connect(\n",
    "        host = host, \n",
    "        user = user, \n",
    "        password = password, \n",
    "        database = database\n",
    "    )\n",
    "    print('success')\n",
    "except connector.Error as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd03f33",
   "metadata": {},
   "source": [
    "Note: the entire CrisisMMD dataset in SQL contains 18,032 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# research_dir = Path(home, 'Desktop', 'Education', 'Spring 2025', 'AI', 'research')\n",
    "research_dir = Path(home, \"ai_research_proj_spring_2025\", \"research_ai_class_spring_2025\") # in lab 409 computer for Agafia\n",
    "os.chdir(research_dir)\n",
    "\n",
    "from data_helper import SQLDataset_Informative\n",
    "\n",
    "os.chdir(home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66b4546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the convnet (Eventually replae with mobile 2)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3) #specify the size (outer numbers) and amount (middle number) of filters\n",
    "        self.pool = nn.MaxPool2d(2, 2) #specify pool size first number is size of pool, second is step size\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3) #new depth is amount of filters in previous conv layer\n",
    "        self.fc1 = nn.Linear(54*54*8, 120)\n",
    "        self.fc2 = nn.Linear(120, 60)\n",
    "        self.fc3 = nn.Linear(60, 3) #finial fc layer needs 19 outputs because we have 19 layers # ???\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "     \n",
    "        x = self.pool(x)\n",
    "       \n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 54*54*8) # flatten\n",
    "\n",
    "        x = F.relu(self.fc1(x))    #fully connected, relu         \n",
    "        x = F.relu(self.fc2(x))    \n",
    "       \n",
    "        x = self.fc3(x)     #output    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639aed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "# transforms\n",
    "transformations = v2.Compose([\n",
    "    v2.RandomResizedCrop(size=(224, 224), antialias=True), \n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5183dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, val, and test sets\n",
    "\n",
    "data_dir=Path('OneDrive - Stephen F. Austin State University', 'CrisisMMD_v2.0','CrisisMMD_v2.0')\n",
    "\n",
    "train_set = SQLDataset_Informative(conn=conn, img_col='image_path', label_col='image_info', transform=transformations, \n",
    "                     data_dir=data_dir, is_train=True)\n",
    "val_set = SQLDataset_Informative(conn=conn, img_col='image_path', label_col='image_info', transform=transformations, \n",
    "                     data_dir=data_dir, is_val=True)\n",
    "test_set = SQLDataset_Informative(conn=conn, img_col='image_path', label_col='image_info', transform=transformations, \n",
    "                     data_dir=data_dir, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99645787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64)\n",
    "val_loader = DataLoader(val_set, batch_size=64)\n",
    "test_loader = DataLoader(test_set, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de20233",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6558ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.forward(set.__getitem__(0)[0])\n",
    "test_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing accuracy metric functions\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e94576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation fn\n",
    "\n",
    "def dev(model, val_loader):\n",
    "    batch_size = val_loader.batch_size\n",
    "    avg = 'macro' # used when computing certain accuracy metrics\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b, batch in tqdm(enumerate(val_loader), \n",
    "                             total= len(val_loader), desc=f\"Processing validation data in batch {b+1}\"):\n",
    "            images = batch['image']\n",
    "            labels = batch['label']\n",
    "\n",
    "            raw_logits = model.forward(images)\n",
    "\n",
    "            preds = nn.LogSoftmax(raw_logits)\n",
    "            preds = np.where(preds >= .5, 1, 0)\n",
    "\n",
    "            loss = nn.CrossEntropyLoss()(raw_logits, labels)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_trues.extend(labels)\n",
    "\n",
    "\n",
    "        # metrics \n",
    "        acc_total = accuracy_score(y_true=all_trues, y_pred=all_preds)\n",
    "        precision = precision_score(y_true=all_trues, y_pred=all_preds, zero_division=1, average=avg)\n",
    "        recall = recall_score(y_true=all_trues, y_pred=all_preds, zero_division=1, average=avg)\n",
    "        f1 = f1_score(y_true=all_trues, y_pred=all_preds, zero_division=1, average=avg)\n",
    "\n",
    "        avg_eval_loss = eval_loss / (len(val_loader)*batch_size)\n",
    "\n",
    "        metrics = {\n",
    "            'accuracy': acc_total, \n",
    "            'precision': precision, \n",
    "            'recall': recall, \n",
    "            'f1': f1, \n",
    "            'avg_eval_loss': avg_eval_loss\n",
    "        }\n",
    "        wandb.log(metrics)\n",
    "        print('****Evaluation****')\n",
    "        print(f'total_accuracy: {acc_total}')\n",
    "\n",
    "        return acc_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0117d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm \n",
    "\n",
    "# #Train the model\n",
    "# model = ConvNet().to(device)\n",
    "\n",
    "# \n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     print('Epoch', epoch)\n",
    "#     for item in tqdm(train_loader, total= len(train_loader), desc=f\"Processing data in epoch {epoch}\"):\n",
    "\n",
    "#         images = item[0]\n",
    "\n",
    "#         labels = item[1]\n",
    "#         assert(labels.shape[0] == images.shape[0])\n",
    "\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model.forward(images)\n",
    "\n",
    "#         loss = cross_entropy(outputs, labels)\n",
    "#         print(f'Train Loss: {loss}')\n",
    "\n",
    "#         # Backward and optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward() # backpropagation\n",
    "#         optimizer.step() # updating parameters\n",
    "        \n",
    "# print('Finished Training')\n",
    "# PATH = research_dir / './cnn.pth'\n",
    "# torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training hyperparameters & functions/tools\n",
    "lr = .001 \n",
    "num_epochs = 500\n",
    "run_name = 'Basic CNN test'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')\n",
    "\n",
    "best_val_acc = 0.0\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) #stocastic gradient descent for our optimization algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ec11330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rosy-bush-1</strong> at: <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/7o606zkr' target=\"_blank\">https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/7o606zkr</a><br> View project at: <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465' target=\"_blank\">https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250424_185928-7o606zkr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\bowdenaa\\ai_research_proj_spring_2025\\research_ai_class_spring_2025\\wandb\\run-20250424_190123-isuwiblq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/isuwiblq' target=\"_blank\">Basic CNN 1</a></strong> to <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465' target=\"_blank\">https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/isuwiblq' target=\"_blank\">https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/isuwiblq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# before training, set up wandb for tracking purposes\n",
    "os.environ[\"WANDB_API_KEY\"] = \"5a08d1ebbf0e86ab877a128b98be3c320301b6a0\"\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"agafiabschool-stephen-f-austin-state-university\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"Research Project for CSCI-1465\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": \"Basic CNN\",\n",
    "        \"dataset\": \"CrisisMMD\",\n",
    "        \"epochs\": num_epochs,\n",
    "    }, name=run_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0576a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to train\n",
    "train_loader.to(device)\n",
    "val_loader.to(device)\n",
    "\n",
    "os.chdir(home)\n",
    "Path(research_dir, 'models' ).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    wandb.log({'epoch', epoch+1})\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for b, batch in tqdm(enumerate(train_loader), \n",
    "                         total= len(train_loader), desc=f\"Processing training data in epoch {epoch}\"):\n",
    "        model.train()\n",
    "        images = batch['image']\n",
    "        labels = batch['label']\n",
    "\n",
    "        model.zero_grad() \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        raw_logits = model.forward(images)\n",
    "        # loss - can use raw logits for this function b/c it applies LogSoftmax \n",
    "        loss = nn.CrossEntropyLoss()(raw_logits, labels)\n",
    "\n",
    "        wandb.log('Train Loss', loss.item())\n",
    "\n",
    "        # backprop!\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (b+1) % 10 == 0:\n",
    "            print(f'batch: {b+1} ; loss: {loss.item()}')\n",
    "    \n",
    "    # each epoch, run validation\n",
    "    acc = dev(model=model, val_loader=val_loader)\n",
    "    \n",
    "    if acc > best_val_acc:\n",
    "        best_val_acc = acc\n",
    "        torch.save(model, Path(research_dir / 'models', {run_name}))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_dict = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22520b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54110eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = ConvNet().load_state_dict(state_dict=loaded_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6eb319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
