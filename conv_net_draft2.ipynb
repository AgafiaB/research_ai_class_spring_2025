{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00fb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary solution to crashing\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3922db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mysql.connector as connector\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import tqdm\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09de19d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "home = os.path.expanduser('~')\n",
    "os.chdir(home) # b/c we will be using universal paths\n",
    "\n",
    "host = '127.0.0.1'\n",
    "user = 'root' # change to your username\n",
    "password = 'vasya1' # change to your password\n",
    "database = 'ai_proj_2025' # for the sake of sanity, we should all have this as the db name \n",
    "\n",
    "try:\n",
    "    conn = connector.connect(\n",
    "        host = host, \n",
    "        user = user, \n",
    "        password = password, \n",
    "        database = database\n",
    "    )\n",
    "    print('success')\n",
    "except connector.Error as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd03f33",
   "metadata": {},
   "source": [
    "Note: the entire CrisisMMD dataset in SQL contains 18,032 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48e1d706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bowdenaa\\ai_research_proj_spring_2025\\research_ai_class_spring_2025\\data_helper.py:28: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(not ((is_train and is_test) or (is_train and is_val) or (is_val and is_test)), 'a dataset can only be one of either train, test, or val')\n"
     ]
    }
   ],
   "source": [
    "# research_dir = Path(home, 'Desktop', 'Education', 'Spring 2025', 'AI', 'research')\n",
    "research_dir = Path(home, \"ai_research_proj_spring_2025\", \"research_ai_class_spring_2025\") # in lab 409 computer for Agafia\n",
    "os.chdir(research_dir)\n",
    "\n",
    "from data_helper import SQLDataset_Informative\n",
    "\n",
    "os.chdir(home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66b4546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the convnet (Eventually replae with mobile 2)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3) #specify the size (outer numbers) and amount (middle number) of filters\n",
    "        self.pool = nn.MaxPool2d(2, 2) #specify pool size first number is size of pool, second is step size\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3) #new depth is amount of filters in previous conv layer\n",
    "        self.fc1 = nn.Linear(54*54*8, 120)\n",
    "        self.fc2 = nn.Linear(120, 60)\n",
    "        self.fc3 = nn.Linear(60, 2) #finial fc layer needs 19 outputs because we have 19 layers # ???\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "     \n",
    "        x = self.pool(x)\n",
    "       \n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 54*54*8) # flatten\n",
    "\n",
    "        x = F.relu(self.fc1(x))    #fully connected, relu         \n",
    "        x = F.relu(self.fc2(x))    \n",
    "       \n",
    "        x = self.fc3(x)     #output    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "639aed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "# transforms\n",
    "transformations = v2.Compose([\n",
    "    v2.RandomResizedCrop(size=(224, 224), antialias=True), \n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5183dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, val, and test sets\n",
    "\n",
    "data_dir=Path('OneDrive - Stephen F. Austin State University', 'CrisisMMD_v2.0','CrisisMMD_v2.0')\n",
    "\n",
    "train_set = SQLDataset_Informative(conn=conn, img_col='image_path', label_col='image_info', transform=transformations, \n",
    "                     data_dir=data_dir, is_train=True)\n",
    "val_set = SQLDataset_Informative(conn=conn, img_col='image_path', label_col='image_info', transform=transformations, \n",
    "                     data_dir=data_dir, is_val=True)\n",
    "test_set = SQLDataset_Informative(conn=conn, img_col='image_path', label_col='image_info', transform=transformations, \n",
    "                     data_dir=data_dir, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41837741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99645787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64)\n",
    "val_loader = DataLoader(val_set, batch_size=64)\n",
    "test_loader = DataLoader(test_set, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2de20233",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6558ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1280, -0.0586]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = model.forward(train_set.__getitem__(0)['image'])\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c14bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing accuracy metric functions\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e94576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation fn\n",
    "\n",
    "def dev(model, val_loader):\n",
    "    model.to(device)\n",
    "    batch_size = val_loader.batch_size\n",
    "    avg = 'macro' # used when computing certain accuracy metrics\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b, batch in tqdm.tqdm(enumerate(val_loader), \n",
    "                             total= len(val_loader), desc=f\"Processing validation data\"):\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            raw_logits = model.forward(images)\n",
    "\n",
    "            preds = torch.argmax(raw_logits, dim=1) # https://discuss.pytorch.org/t/cross-entropy-loss-get-predicted-class/58215\n",
    "\n",
    "            loss = nn.CrossEntropyLoss()(raw_logits, labels)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_trues.extend(labels.tolist())\n",
    "\n",
    "\n",
    "        # metrics \n",
    "        acc_total = accuracy_score(y_true=all_trues, y_pred=all_preds)\n",
    "        precision = precision_score(y_true=all_trues, y_pred=all_preds, zero_division=1, average=avg)\n",
    "        recall = recall_score(y_true=all_trues, y_pred=all_preds, zero_division=1, average=avg)\n",
    "        f1 = f1_score(y_true=all_trues, y_pred=all_preds, zero_division=1, average=avg)\n",
    "\n",
    "        avg_eval_loss = eval_loss / (len(val_loader)*batch_size)\n",
    "\n",
    "        metrics = {\n",
    "            'accuracy': acc_total, \n",
    "            'precision': precision, \n",
    "            'recall': recall, \n",
    "            'f1': f1, \n",
    "            'avg_eval_loss': avg_eval_loss\n",
    "        }\n",
    "        wandb.log(metrics)\n",
    "        print('****Evaluation****')\n",
    "        print(f'total_accuracy: {acc_total}')\n",
    "\n",
    "        return acc_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d0117d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm \n",
    "\n",
    "# #Train the model\n",
    "# model = ConvNet().to(device)\n",
    "\n",
    "# \n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     print('Epoch', epoch)\n",
    "#     for item in tqdm(train_loader, total= len(train_loader), desc=f\"Processing data in epoch {epoch}\"):\n",
    "\n",
    "#         images = item[0]\n",
    "\n",
    "#         labels = item[1]\n",
    "#         assert(labels.shape[0] == images.shape[0])\n",
    "\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model.forward(images)\n",
    "\n",
    "#         loss = cross_entropy(outputs, labels)\n",
    "#         print(f'Train Loss: {loss}')\n",
    "\n",
    "#         # Backward and optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward() # backpropagation\n",
    "#         optimizer.step() # updating parameters\n",
    "        \n",
    "# print('Finished Training')\n",
    "# PATH = research_dir / './cnn.pth'\n",
    "# torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d2d511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "# training hyperparameters & functions/tools\n",
    "lr = .001 \n",
    "num_epochs = 500\n",
    "run_name = 'Basic CNN test'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')\n",
    "\n",
    "best_val_acc = 0.0\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) #stocastic gradient descent for our optimization algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ec11330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>▁▅▆█▇▃</td></tr><tr><td>epoch</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.54165</td></tr><tr><td>epoch</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Basic CNN test</strong> at: <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/706cvu8o' target=\"_blank\">https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/706cvu8o</a><br> View project at: <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465' target=\"_blank\">https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250424_221906-706cvu8o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\bowdenaa\\wandb\\run-20250424_222039-gwz7w67h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/gwz7w67h' target=\"_blank\">Basic CNN test</a></strong> to <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465' target=\"_blank\">https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/gwz7w67h' target=\"_blank\">https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/gwz7w67h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# before training, set up wandb for tracking purposes\n",
    "os.environ[\"WANDB_API_KEY\"] = \"5a08d1ebbf0e86ab877a128b98be3c320301b6a0\"\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"agafiabschool-stephen-f-austin-state-university\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"Research Project for CSCI-1465\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": \"Basic CNN\",\n",
    "        \"dataset\": \"CrisisMMD\",\n",
    "        \"epochs\": num_epochs,\n",
    "    }, name=run_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0576a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1: 100%|██████████| 6/6 [00:01<00:00,  4.26it/s]\n",
      "Processing validation data: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ; loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# each epoch, run validation\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m acc \u001b[38;5;241m=\u001b[39m dev(model\u001b[38;5;241m=\u001b[39mmodel, val_loader\u001b[38;5;241m=\u001b[39mval_loader)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m acc \u001b[38;5;241m>\u001b[39m best_val_acc:\n\u001b[0;32m     40\u001b[0m     best_val_acc \u001b[38;5;241m=\u001b[39m acc\n",
      "Cell \u001b[1;32mIn[30], line 33\u001b[0m, in \u001b[0;36mdev\u001b[1;34m(model, val_loader)\u001b[0m\n\u001b[0;32m     29\u001b[0m     all_trues\u001b[38;5;241m.\u001b[39mextend(labels)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# metrics \u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m acc_total \u001b[38;5;241m=\u001b[39m accuracy_score(y_true\u001b[38;5;241m=\u001b[39mall_trues\u001b[38;5;241m.\u001b[39mcpu(), y_pred\u001b[38;5;241m=\u001b[39mall_preds\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[0;32m     34\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(y_true\u001b[38;5;241m=\u001b[39mall_trues\u001b[38;5;241m.\u001b[39mcpu(), y_pred\u001b[38;5;241m=\u001b[39mall_preds\u001b[38;5;241m.\u001b[39mcpu(), zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, average\u001b[38;5;241m=\u001b[39mavg)\n\u001b[0;32m     35\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_true\u001b[38;5;241m=\u001b[39mall_trues\u001b[38;5;241m.\u001b[39mcpu(), y_pred\u001b[38;5;241m=\u001b[39mall_preds\u001b[38;5;241m.\u001b[39mcpu(), zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, average\u001b[38;5;241m=\u001b[39mavg)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "# time to train\n",
    "model.to(device)\n",
    "os.chdir(home)\n",
    "Path(research_dir, 'models' ).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    wandb.log({'epoch': epoch+1})\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for b, batch in tqdm.tqdm(enumerate(train_loader), \n",
    "                         total= len(train_loader), desc=f\"Processing training data in epoch {epoch+1}\"):\n",
    "        model.train()\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        model.zero_grad() \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        raw_logits = model.forward(images)\n",
    "        # loss - can use raw logits for this function b/c it applies LogSoftmax \n",
    "        loss = nn.CrossEntropyLoss()(raw_logits, labels)\n",
    "\n",
    "        wandb.log({'Train Loss': loss.item()})\n",
    "\n",
    "        # backprop!\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (b+1) % 10 == 0:\n",
    "            print(f'batch: {b+1} ; loss: {loss.item()}')\n",
    "    \n",
    "    # each epoch, run validation\n",
    "    acc = dev(model=model, val_loader=val_loader)\n",
    "    \n",
    "    if acc > best_val_acc:\n",
    "        best_val_acc = acc\n",
    "        torch.save(model, Path(research_dir / 'models', {run_name}))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_dict = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22520b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54110eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = ConvNet().load_state_dict(state_dict=loaded_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6eb319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
