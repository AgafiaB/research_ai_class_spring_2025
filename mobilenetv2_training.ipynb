{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e60e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary solution to crashing\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b168c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model_helper import MobileNetV2, Inv2d\n",
    "import wandb\n",
    "import mysql.connector as connector\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision.models import mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bdb1304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "home = os.path.expanduser('~')\n",
    "os.chdir(home) # b/c we will be using universal paths\n",
    "\n",
    "host = '127.0.0.1'\n",
    "user = 'root' # change to your username\n",
    "password = 'ethan1' # change to your password\n",
    "database = 'ai_proj_2025' # we should all have this as the db name \n",
    "\n",
    "try:\n",
    "    conn = connector.connect(\n",
    "        host = host, \n",
    "        user = user, \n",
    "        password = password, \n",
    "        database = database\n",
    "    )\n",
    "    print('success')\n",
    "except connector.Error as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131056b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0330c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#research_dir = Path(home, 'Desktop', 'Education', 'Spring 2025', 'AI', 'research_ai_class_spring_2025')\n",
    "research_dir = Path(home, \"ai_research_proj_spring_2025\", \"research_ai_class_spring_2025\") # in lab 409 computer for Agafia\n",
    "os.chdir(research_dir)\n",
    "\n",
    "from data_helper import SQLDataset_Informative\n",
    "\n",
    "os.chdir(home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf83da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "# transforms\n",
    "transformations = v2.Compose([\n",
    "    v2.RandomResizedCrop(size=(224, 224), antialias=True), \n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed1acb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, val, and test sets\n",
    "\n",
    "data_dir=Path(home, 'crisis_npl_data', 'CrisisMMD_v2.0', 'CrisisMMD_v2.0')\n",
    "\n",
    "train_set = SQLDataset_Informative(conn=conn, img_col='image_path', label_col='image_info', transform=transformations, \n",
    "                     data_dir=data_dir, is_train=True)\n",
    "val_set = SQLDataset_Informative(conn=conn, img_col='image_path', label_col='image_info', transform=transformations, \n",
    "                     data_dir=data_dir, is_val=True)\n",
    "test_set = SQLDataset_Informative(conn=conn, img_col='image_path', label_col='image_info', transform=transformations, \n",
    "                     data_dir=data_dir, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf33fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_2points = [train_set.__getitem__(i) for i in range(2)]\n",
    "val_set_2points = [val_set.__getitem__(i) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22567c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
<<<<<<< HEAD
    "train_loader = DataLoader(train_set, batch_size=256)\n",
    "val_loader = DataLoader(val_set, batch_size=128)\n",
    "test_loader = DataLoader(test_set, batch_size=128)\n",
    "\n",
    "# for data in train_loader:\n",
    "#     print(data['label'])"
=======
    "train_loader = DataLoader(train_set, batch_size=64)\n",
    "val_loader = DataLoader(val_set, batch_size=64)\n",
    "test_loader = DataLoader(test_set, batch_size=128)"
>>>>>>> ec5f486e172c6dc95e8142882a7d2811e5986d0e
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "957a3b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING - will uncomment later\n",
    "\n",
    "# # instantiate our model\n",
    "# model_test = MobileNetV2()\n",
    "\n",
    "# conv_start = nn.Conv2d(3, 3, kernel_size=3, padding='same')\n",
    "# conv_end = nn.Conv2d(96, 96, kernel_size=3, padding='same')\n",
    "\n",
    "#     # load pretrained weights\n",
    "# pretrained = mobilenet_v2(weights='IMAGENET1K_V2')\n",
    "# weights = pretrained.state_dict()\n",
    "# model_test.features.load_state_dict(weights, strict=False)\n",
    "\n",
    "#     # turn off all but the topmost layers\n",
    "# freeze_up_to = 12\n",
    "# for param in model_test.features[:freeze_up_to].parameters(): \n",
    "#     param.requires_grad = False\n",
    "    \n",
    "# model_test = nn.Sequential( conv_start, nn.BatchNorm2d(3), nn.ReLU(),model_test, nn.Linear(1280, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47139380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing accuracy metric functions\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07726630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d369ac3",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Make sure to change the run_name (and 'architecture' parameter of the wandb `run` variable if necessary) with each new run. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 13,
>>>>>>> ec5f486e172c6dc95e8142882a7d2811e5986d0e
   "id": "edb3f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation fn\n",
    "\n",
    "def dev(model, val_loader):\n",
    "    model.to(device)\n",
    "    batch_size = val_loader.batch_size\n",
    "    avg = 'macro' # used when computing certain accuracy metrics\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b, batch in tqdm.tqdm(enumerate(val_loader), \n",
    "                             total= len(val_loader), desc=f\"Processing validation data\"):\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            raw_logits = model.forward(images)\n",
    "\n",
    "            preds = torch.argmax(raw_logits, dim=1) # https://discuss.pytorch.org/t/cross-entropy-loss-get-predicted-class/58215\n",
    "\n",
    "            loss = nn.CrossEntropyLoss()(raw_logits, labels)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_trues.extend(labels.tolist())\n",
    "\n",
    "\n",
    "        # metrics \n",
    "        acc_total = accuracy_score(y_true=all_trues, y_pred=all_preds)\n",
    "        precision = precision_score(y_true=all_trues, y_pred=all_preds, zero_division=0, average=avg)\n",
    "        recall = recall_score(y_true=all_trues, y_pred=all_preds, zero_division=0, average=avg)\n",
    "        f1 = f1_score(y_true=all_trues, y_pred=all_preds, zero_division=0, average=avg)\n",
    "\n",
    "        avg_eval_loss = eval_loss / (len(val_loader))\n",
    "\n",
    "        metrics = {\n",
    "            'accuracy': acc_total, \n",
    "            'precision': precision, \n",
    "            'recall': recall, \n",
    "            'f1': f1, \n",
    "            'avg_eval_loss': avg_eval_loss\n",
    "        }\n",
    "        wandb.log(metrics)\n",
    "        print('****Evaluation****')\n",
    "        print(f'total_accuracy: {acc_total}')\n",
    "\n",
    "        return acc_total\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 14,
>>>>>>> ec5f486e172c6dc95e8142882a7d2811e5986d0e
   "id": "54ec2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(model, num_epochs, run_name, lr, architecture, frozen_layers):\n",
    "    # training hyperparameters & functions/tools\n",
    "    lr = lr \n",
    "    num_epochs = num_epochs\n",
    "    run_name = run_name\n",
    "    \n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) #stocastic gradient descent for our optimization algorithm\n",
    "    lr_sched = MultiStepLR(optimizer=optimizer, milestones=list(range(50, num_epochs, 30)), gamma=.1)\n",
    "\n",
    "    model.to(device)\n",
    "    # for saving the models\n",
    "    Path(research_dir, 'models' ).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # before training, set up wandb for tracking purposes\n",
    "    os.environ[\"WANDB_API_KEY\"] = \"5a08d1ebbf0e86ab877a128b98be3c320301b6a0\"\n",
    "\n",
    "    run = wandb.init(\n",
    "        # Set the wandb entity where your project will be logged (generally your team name).\n",
    "        entity=\"agafiabschool-stephen-f-austin-state-university\",\n",
    "        # Set the wandb project where this run will be logged.\n",
    "        project=\"Research Project for CSCI-1465\",\n",
    "        # Track hyperparameters and run metadata.\n",
    "        config={\n",
    "            \"learning_rate\": lr,\n",
    "            \"architecture\": architecture,\n",
    "            \"dataset\": \"CrisisMMD\",\n",
    "            \"epochs\": num_epochs,\n",
    "            'frozen_layers': frozen_layers,\n",
    "        }, name=run_name\n",
    "    )\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        wandb.log({'epoch': epoch+1})\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for b, batch in tqdm.tqdm(enumerate(train_loader), \n",
    "                            total= len(train_loader), desc=f\"Processing training data in epoch {epoch+1}\"):\n",
    "            model.train()\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            model.zero_grad() \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            raw_logits = model.forward(images)\n",
    "            # loss - can use raw logits for this function b/c it applies LogSoftmax \n",
    "            loss = nn.CrossEntropyLoss()(raw_logits, labels)\n",
    "            print(f'Train Loss: {loss}')\n",
    "            wandb.log({'Train Loss': loss.item()})\n",
    "            wandb.log({'LR': lr_sched.get_last_lr()[0]})\n",
    "\n",
    "\n",
    "            # backprop!\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if (b+1) % 20 == 0:\n",
    "                print(f'batch: {b+1} ; loss: {loss.item()}')\n",
    "        \n",
    "        # each epoch, run validation\n",
    "        acc = dev(model=model, val_loader=val_loader)\n",
    "        \n",
    "        if acc > best_val_acc:\n",
    "            best_val_acc = acc\n",
    "            torch.save(model, Path(research_dir, 'models', f'{run_name}'))\n",
    "        \n",
    "        lr_sched.step()\n",
    "    \n",
    "    return best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0afdde5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, images, class_names=None):\n",
    "    raw_logits = model.forward(images)\n",
    "    preds = torch.argmax(raw_logits, dim=1)\n",
    "    if class_names is None:\n",
    "        return list(preds)\n",
    "    \n",
    "    try: \n",
    "        preds = [class_names[pred] for pred in preds]\n",
    "        return preds\n",
    "    except IndexError as e:\n",
    "        print(f'Class names do not match the prediction indices. Error Message: {e}')\n",
    "    except:\n",
    "        print(f'Error Message: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f740a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class_names = ['not informative', 'informative']\n",
    "\n",
    "# image1 = torch.unsqueeze(val_set.__getitem__(0)['image'], 0)\n",
    "# image2 = torch.unsqueeze(val_set.__getitem__(1)['image'], 0)\n",
    "# images = torch.concat((image1, image2), dim=0)\n",
    "# print(images.shape)\n",
    "# pred = predict(model_test, images, class_names=class_names)\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639cafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_residual_setting = [\n",
    "                # t - expansion factor, c - # of output after block, n - # of repitions, s - stride\n",
    "                [1, 16, 1, 1],\n",
    "                [6, 24, 2, 2],\n",
    "                # [6, 32, 3, 2],\n",
    "                # [6, 64, 4, 2],\n",
    "                # [6, 96, 3, 1],\n",
    "                # [6, 160, 3, 2],\n",
    "                # [6, 320, 1, 1],\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38971e32",
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: agafiabschool (agafiabschool-stephen-f-austin-state-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\bowdenaa\\wandb\\run-20250505_091832-j9bmgll5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/j9bmgll5' target=\"_blank\">MobileNetV2-extra fc-12 layers frozen-lr=0.01</a></strong> to <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465' target=\"_blank\">https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/j9bmgll5' target=\"_blank\">https://wandb.ai/agafiabschool-stephen-f-austin-state-university/Research%20Project%20for%20CSCI-1465/runs/j9bmgll5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7218270301818848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:   2%|▏         | 1/64 [00:01<01:13,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11.410585403442383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:   3%|▎         | 2/64 [00:02<01:02,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6918773651123047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:   5%|▍         | 3/64 [00:02<00:57,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8927452564239502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:   6%|▋         | 4/64 [00:03<00:54,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.85882568359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:   8%|▊         | 5/64 [00:04<00:52,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6964230537414551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:   9%|▉         | 6/64 [00:05<00:51,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8264205455780029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  11%|█         | 7/64 [00:06<00:54,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6580492854118347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  12%|█▎        | 8/64 [00:07<00:52,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7443516254425049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  14%|█▍        | 9/64 [00:08<00:50,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7125269174575806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  16%|█▌        | 10/64 [00:09<00:49,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6841172575950623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  17%|█▋        | 11/64 [00:10<00:48,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6896973252296448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  19%|█▉        | 12/64 [00:11<00:49,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6963452100753784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  20%|██        | 13/64 [00:12<00:47,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6939346194267273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  22%|██▏       | 14/64 [00:13<00:46,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6895838379859924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  23%|██▎       | 15/64 [00:14<00:45,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7081179022789001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  25%|██▌       | 16/64 [00:15<00:45,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6921640038490295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  27%|██▋       | 17/64 [00:16<00:46,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6980929970741272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  28%|██▊       | 18/64 [00:17<00:45,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7121042013168335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  30%|██▉       | 19/64 [00:18<00:46,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7039636969566345\n",
      "batch: 20 ; loss: 0.7039636969566345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  31%|███▏      | 20/64 [00:19<00:44,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6916368007659912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  33%|███▎      | 21/64 [00:20<00:42,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.726708173751831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  34%|███▍      | 22/64 [00:20<00:40,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7255922555923462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  36%|███▌      | 23/64 [00:22<00:39,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6949336528778076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  38%|███▊      | 24/64 [00:22<00:37,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6914989352226257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  39%|███▉      | 25/64 [00:23<00:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7018319368362427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  41%|████      | 26/64 [00:24<00:36,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7003845572471619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  42%|████▏     | 27/64 [00:25<00:35,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7000763416290283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  44%|████▍     | 28/64 [00:26<00:35,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7044384479522705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  45%|████▌     | 29/64 [00:27<00:34,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7022278904914856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  47%|████▋     | 30/64 [00:29<00:35,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.698256254196167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  48%|████▊     | 31/64 [00:29<00:33,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6928873062133789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  50%|█████     | 32/64 [00:30<00:32,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6904833316802979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  52%|█████▏    | 33/64 [00:31<00:30,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6920599937438965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  53%|█████▎    | 34/64 [00:33<00:30,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6862242221832275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  55%|█████▍    | 35/64 [00:34<00:29,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6827856302261353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  56%|█████▋    | 36/64 [00:34<00:27,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6824744343757629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  58%|█████▊    | 37/64 [00:35<00:26,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8086464405059814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  59%|█████▉    | 38/64 [00:36<00:24,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7548773288726807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  61%|██████    | 39/64 [00:37<00:23,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7217420339584351\n",
      "batch: 40 ; loss: 0.7217420339584351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  62%|██████▎   | 40/64 [00:38<00:23,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7034041881561279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  64%|██████▍   | 41/64 [00:39<00:22,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6961833834648132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  66%|██████▌   | 42/64 [00:40<00:20,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6934759020805359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  67%|██████▋   | 43/64 [00:41<00:20,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6920322179794312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  69%|██████▉   | 44/64 [00:42<00:19,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6962329149246216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  70%|███████   | 45/64 [00:43<00:18,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6997331976890564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  72%|███████▏  | 46/64 [00:44<00:17,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6999122500419617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  73%|███████▎  | 47/64 [00:45<00:17,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6925843954086304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  75%|███████▌  | 48/64 [00:46<00:15,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6915215253829956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  77%|███████▋  | 49/64 [00:47<00:14,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6893611550331116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  78%|███████▊  | 50/64 [00:48<00:13,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6787558794021606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  80%|███████▉  | 51/64 [00:49<00:12,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6604776382446289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  81%|████████▏ | 52/64 [00:50<00:12,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6480578184127808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  83%|████████▎ | 53/64 [00:51<00:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8410372138023376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  84%|████████▍ | 54/64 [00:52<00:09,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8195939660072327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  86%|████████▌ | 55/64 [00:53<00:08,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7662744522094727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  88%|████████▊ | 56/64 [00:53<00:07,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7176604270935059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  89%|████████▉ | 57/64 [00:54<00:06,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6899202466011047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  91%|█████████ | 58/64 [00:55<00:05,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6904429197311401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  92%|█████████▏| 59/64 [00:56<00:04,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7011823654174805\n",
      "batch: 60 ; loss: 0.7011823654174805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  94%|█████████▍| 60/64 [00:57<00:03,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7034569978713989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  95%|█████████▌| 61/64 [00:58<00:02,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7552797794342041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  97%|█████████▋| 62/64 [00:59<00:01,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7590327858924866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1:  98%|█████████▊| 63/64 [01:00<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7212331891059875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 1: 100%|██████████| 64/64 [01:00<00:00,  1.05it/s]\n",
      "Processing validation data: 100%|██████████| 8/8 [00:03<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Evaluation****\n",
      "total_accuracy: 0.5265486725663717\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6918171644210815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:   2%|▏         | 1/64 [00:00<00:52,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6921216249465942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:   3%|▎         | 2/64 [00:01<00:54,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6915611028671265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:   5%|▍         | 3/64 [00:02<00:52,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6891884207725525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:   6%|▋         | 4/64 [00:03<00:51,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6922202706336975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:   8%|▊         | 5/64 [00:04<00:54,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6864960193634033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:   9%|▉         | 6/64 [00:05<00:51,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6602634191513062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  11%|█         | 7/64 [00:06<00:50,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6613255739212036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  12%|█▎        | 8/64 [00:07<00:49,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6710488200187683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  14%|█▍        | 9/64 [00:07<00:48,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.677570104598999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  16%|█▌        | 10/64 [00:08<00:47,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.697566032409668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  17%|█▋        | 11/64 [00:09<00:49,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.70932537317276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  19%|█▉        | 12/64 [00:10<00:46,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.708563506603241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  20%|██        | 13/64 [00:11<00:45,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6948946118354797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  22%|██▏       | 14/64 [00:12<00:43,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.701604425907135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  23%|██▎       | 15/64 [00:13<00:43,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6881113052368164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  25%|██▌       | 16/64 [00:14<00:43,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6913948059082031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  27%|██▋       | 17/64 [00:15<00:44,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.692908525466919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  28%|██▊       | 18/64 [00:16<00:41,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6933732032775879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  30%|██▉       | 19/64 [00:16<00:40,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6927001476287842\n",
      "batch: 20 ; loss: 0.6927001476287842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  31%|███▏      | 20/64 [00:17<00:39,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6879982948303223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  33%|███▎      | 21/64 [00:18<00:38,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8245053887367249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  34%|███▍      | 22/64 [00:19<00:37,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7243929505348206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  36%|███▌      | 23/64 [00:20<00:37,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6932615637779236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  38%|███▊      | 24/64 [00:21<00:36,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6931121349334717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  39%|███▉      | 25/64 [00:22<00:35,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6933428645133972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  41%|████      | 26/64 [00:23<00:34,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6932638883590698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  42%|████▏     | 27/64 [00:24<00:33,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6929796934127808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  44%|████▍     | 28/64 [00:25<00:34,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6943653225898743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  45%|████▌     | 29/64 [00:26<00:32,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6945111751556396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  47%|████▋     | 30/64 [00:27<00:31,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6955165863037109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  48%|████▊     | 31/64 [00:27<00:30,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6934686899185181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  50%|█████     | 32/64 [00:28<00:29,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6943500638008118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  52%|█████▏    | 33/64 [00:29<00:28,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.69343501329422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  53%|█████▎    | 34/64 [00:30<00:28,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6940151453018188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  55%|█████▍    | 35/64 [00:31<00:27,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.693446695804596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  56%|█████▋    | 36/64 [00:32<00:25,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6929867267608643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  58%|█████▊    | 37/64 [00:33<00:24,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6958351135253906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  59%|█████▉    | 38/64 [00:34<00:23,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6952767968177795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  61%|██████    | 39/64 [00:35<00:22,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6944501399993896\n",
      "batch: 40 ; loss: 0.6944501399993896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  62%|██████▎   | 40/64 [00:36<00:22,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6922218799591064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  64%|██████▍   | 41/64 [00:37<00:21,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6907346844673157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  66%|██████▌   | 42/64 [00:37<00:19,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6896642446517944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  67%|██████▋   | 43/64 [00:38<00:18,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6909123659133911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  69%|██████▉   | 44/64 [00:39<00:18,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.699415922164917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  70%|███████   | 45/64 [00:40<00:18,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7038313746452332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  72%|███████▏  | 46/64 [00:41<00:16,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7091811895370483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  73%|███████▎  | 47/64 [00:42<00:15,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7072451710700989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  75%|███████▌  | 48/64 [00:43<00:14,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7054769992828369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  77%|███████▋  | 49/64 [00:44<00:13,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7002102732658386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  78%|███████▊  | 50/64 [00:45<00:12,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.704175591468811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  80%|███████▉  | 51/64 [00:46<00:11,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.703819990158081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  81%|████████▏ | 52/64 [00:47<00:11,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7004778981208801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  83%|████████▎ | 53/64 [00:48<00:11,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.689018964767456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  84%|████████▍ | 54/64 [00:49<00:09,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6902864575386047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  86%|████████▌ | 55/64 [00:50<00:08,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6911640167236328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  88%|████████▊ | 56/64 [00:50<00:07,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6916646957397461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  89%|████████▉ | 57/64 [00:51<00:06,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6918125152587891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  91%|█████████ | 58/64 [00:53<00:06,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6924378275871277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  92%|█████████▏| 59/64 [00:54<00:05,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6951422095298767\n",
      "batch: 60 ; loss: 0.6951422095298767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  94%|█████████▍| 60/64 [00:55<00:04,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6933885216712952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  95%|█████████▌| 61/64 [00:57<00:03,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6985989212989807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  97%|█████████▋| 62/64 [00:58<00:02,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7084997892379761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2:  98%|█████████▊| 63/64 [01:00<00:01,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.698136031627655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 2: 100%|██████████| 64/64 [01:01<00:00,  1.04it/s]\n",
      "Processing validation data: 100%|██████████| 8/8 [00:04<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Evaluation****\n",
      "total_accuracy: 0.47345132743362833\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6940957307815552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:   2%|▏         | 1/64 [00:01<01:21,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6960132122039795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:   3%|▎         | 2/64 [00:02<01:16,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6954054236412048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:   5%|▍         | 3/64 [00:03<01:11,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.69631028175354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:   6%|▋         | 4/64 [00:04<01:10,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6940943002700806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:   8%|▊         | 5/64 [00:05<01:08,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.695367693901062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:   9%|▉         | 6/64 [00:07<01:08,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6986241340637207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:  11%|█         | 7/64 [00:08<01:11,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6960924863815308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:  12%|█▎        | 8/64 [00:09<01:04,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6942453980445862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:  14%|█▍        | 9/64 [00:10<00:59,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6933473348617554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:  16%|█▌        | 10/64 [00:11<00:58,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6925193667411804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:  17%|█▋        | 11/64 [00:12<00:53,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6923511624336243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:  19%|█▉        | 12/64 [00:13<00:50,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.692833423614502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data in epoch 3:  20%|██        | 13/64 [00:14<00:57,  1.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(model, nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m1280\u001b[39m, \u001b[38;5;241m512\u001b[39m), nn\u001b[38;5;241m.\u001b[39mReLU(), nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m128\u001b[39m), nn\u001b[38;5;241m.\u001b[39mReLU(), nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;66;03m# 1280 is the num of features outputted by MobileNetv2 after flattening\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m acc \u001b[38;5;241m=\u001b[39m train_eval(model, num_epochs, run_name, lr\u001b[38;5;241m=\u001b[39mlr, architecture\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMobileNetV2\u001b[39m\u001b[38;5;124m'\u001b[39m, frozen_layers\u001b[38;5;241m=\u001b[39mfreeze_up_to)\n\u001b[0;32m     31\u001b[0m my_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m acc\n\u001b[0;32m     32\u001b[0m history\u001b[38;5;241m.\u001b[39mappend(my_dict)\n",
      "Cell \u001b[1;32mIn[12], line 41\u001b[0m, in \u001b[0;36mtrain_eval\u001b[1;34m(model, num_epochs, run_name, lr, architecture, frozen_layers)\u001b[0m\n\u001b[0;32m     37\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m})\n\u001b[0;32m     39\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b, batch \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader), \n\u001b[0;32m     42\u001b[0m                     total\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing training data in epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     43\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     44\u001b[0m     images \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\bowdenaa\\AppData\\Local\\anaconda3\\envs\\torch\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bowdenaa\\AppData\\Local\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\bowdenaa\\AppData\\Local\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\bowdenaa\\AppData\\Local\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\ai_research_proj_spring_2025\\research_ai_class_spring_2025\\data_helper.py:106\u001b[0m, in \u001b[0;36mSQLDataset_Informative.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    104\u001b[0m img_path, label \u001b[38;5;241m=\u001b[39m cursor\u001b[38;5;241m.\u001b[39mfetchone()\n\u001b[0;32m    105\u001b[0m img_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir, img_path)\n\u001b[1;32m--> 106\u001b[0m image \u001b[38;5;241m=\u001b[39m decode_image(img_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# returns (Tensor[image_channels, image_height, image_width])\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minformative\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    110\u001b[0m     label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bowdenaa\\AppData\\Local\\anaconda3\\envs\\torch\\Lib\\site-packages\\torchvision\\io\\image.py:318\u001b[0m, in \u001b[0;36mdecode_image\u001b[1;34m(input, mode, apply_exif_orientation)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mode, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    317\u001b[0m     mode \u001b[38;5;241m=\u001b[39m ImageReadMode[mode\u001b[38;5;241m.\u001b[39mupper()]\n\u001b[1;32m--> 318\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdecode_image(\u001b[38;5;28minput\u001b[39m, mode\u001b[38;5;241m.\u001b[39mvalue, apply_exif_orientation)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\bowdenaa\\AppData\\Local\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> ec5f486e172c6dc95e8142882a7d2811e5986d0e
   "source": [
    "# time to train\n",
    "\n",
    "# model_test = MobileNetV2()\n",
    "\n",
    "# conv_start = nn.Conv2d(3, 3, kernel_size=3, padding='same')\n",
    "# conv_end = nn.Conv2d(96, 96, kernel_size=3, padding='same')\n",
    "\n",
    "#     # load pretrained weights\n",
    "# pretrained = mobilenet_v2(weights='IMAGENET1K_V2')\n",
    "# weights = pretrained.state_dict()\n",
    "# model_test.features.load_state_dict(weights, strict=False)\n",
    "\n",
    "#     # turn off all but the topmost layers\n",
    "# freeze_up_to = 12\n",
    "# for param in model_test.features[:freeze_up_to].parameters(): \n",
    "#     param.requires_grad = False\n",
    "    \n",
    "# model_test = nn.Sequential( conv_start, nn.BatchNorm2d(3), nn.ReLU(),model_test, nn.Linear(1280, 2))\n",
    "\n",
    "\n",
    "num_epochs = 200\n",
    "os.chdir(home)\n",
    "\n",
    "# for grid-search\n",
    "history = []\n",
    "# for lr in [10**-4, 30**-4, 10**-3, 30**-3, 10**-2, 30**-2, 10**-1, 30**-1, 1]:\n",
    "for lr in [10**-2, 10**-1, 30**-1, 1]:\n",
    "    # run_name = f'MobileNetV2 lr={lr}'\n",
    "    run_name = f'MobileNetV2-extra fc-12 layers frozen-lr={lr}'\n",
    "    my_dict = {}\n",
    "    my_dict['lr'] = lr\n",
    "\n",
    "    # instantiate our model\n",
<<<<<<< HEAD
    "    model = MobileNetV2(inverted_residual_setting=inverted_residual_setting)\n",
    "    \n",
=======
    "    model = MobileNetV2()\n",
>>>>>>> ec5f486e172c6dc95e8142882a7d2811e5986d0e
    "\n",
    "    # load pretrained weights\n",
    "    pretrained = mobilenet_v2(weights='IMAGENET1K_V2')\n",
    "    weights = pretrained.state_dict()\n",
    "    model.features.load_state_dict(weights, strict=False)\n",
    "\n",
    "    # turn off all but the topmost layers\n",
    "    freeze_up_to = 12\n",
    "    for param in model.features[:freeze_up_to].parameters(): \n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model = nn.Sequential(model, nn.Linear(1280, 512), nn.ReLU(), nn.Linear(512, 128), nn.ReLU(), nn.Linear(128, 2)) # 1280 is the num of features outputted by MobileNetv2 after flattening\n",
    "    \n",
    "    acc = train_eval(model, num_epochs, run_name, lr=lr, architecture='MobileNetV2', frozen_layers=freeze_up_to)\n",
    "    my_dict['acc'] = acc\n",
    "    history.append(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3eba19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
