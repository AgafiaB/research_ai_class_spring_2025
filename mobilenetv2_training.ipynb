{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e60e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary solution to crashing\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b168c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model_helper import MobileNetV2, Inv2d\n",
    "import wandb\n",
    "import mysql.connector as connector\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision.models import mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb1304",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser('~')\n",
    "os.chdir(home) # b/c we will be using universal paths\n",
    "\n",
    "host = '127.0.0.1'\n",
    "user = 'root' # change to your username\n",
    "password = 'vasya1' # change to your password\n",
    "database = 'ai_proj_2025' # we should all have this as the db name \n",
    "\n",
    "try:\n",
    "    conn = connector.connect(\n",
    "        host = host, \n",
    "        user = user, \n",
    "        password = password, \n",
    "        database = database\n",
    "    )\n",
    "    print('success')\n",
    "except connector.Error as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131056b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0330c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# research_dir = Path(home, 'Desktop', 'Education', 'Spring 2025', 'AI', 'research')\n",
    "research_dir = Path(home, \"ai_research_proj_spring_2025\", \"research_ai_class_spring_2025\") # in lab 409 computer for Agafia\n",
    "os.chdir(research_dir)\n",
    "\n",
    "from data_helper import SQLDataset_Informative\n",
    "\n",
    "os.chdir(home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf83da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "# transforms\n",
    "transformations = v2.Compose([\n",
    "    v2.RandomResizedCrop(size=(224, 224), antialias=True), \n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1acb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, val, and test sets\n",
    "\n",
    "data_dir=Path('OneDrive - Stephen F. Austin State University', 'CrisisMMD_v2.0','CrisisMMD_v2.0')\n",
    "\n",
    "train_set = SQLDataset_Informative(conn=conn, img_col='image_path', label_col='image_info', transform=transformations, \n",
    "                     data_dir=data_dir, is_train=True, table_name='Hurricane_Images')\n",
    "val_set = SQLDataset_Informative(conn=conn, img_col='image_path', label_col='image_info', transform=transformations, \n",
    "                     data_dir=data_dir, is_val=True, table_name='Hurricane_Images')\n",
    "test_set = SQLDataset_Informative(conn=conn, img_col='image_path', label_col='image_info', transform=transformations, \n",
    "                     data_dir=data_dir, is_test=True, table_name='Hurricane_Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_2points = [train_set.__getitem__(i) for i in range(2)]\n",
    "val_set_2points = [val_set.__getitem__(i) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22567c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=256)\n",
    "val_loader = DataLoader(val_set, batch_size=128)\n",
    "test_loader = DataLoader(test_set, batch_size=128)\n",
    "\n",
    "# for data in train_loader:\n",
    "#     print(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47139380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing accuracy metric functions\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07726630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d369ac3",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Make sure to change the run_name (and 'architecture' parameter of the wandb `run` variable if necessary) with each new run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation fn\n",
    "\n",
    "def dev(model, val_loader):\n",
    "    model.to(device)\n",
    "    batch_size = val_loader.batch_size\n",
    "    avg = 'macro' # used when computing certain accuracy metrics\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b, batch in tqdm.tqdm(enumerate(val_loader), \n",
    "                             total= len(val_loader), desc=f\"Processing validation data\"):\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            raw_logits = model.forward(images)\n",
    "\n",
    "            preds = torch.argmax(raw_logits, dim=1) # https://discuss.pytorch.org/t/cross-entropy-loss-get-predicted-class/58215\n",
    "\n",
    "            loss = nn.CrossEntropyLoss()(raw_logits, labels)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_trues.extend(labels.tolist())\n",
    "\n",
    "\n",
    "        # metrics \n",
    "        acc_total = accuracy_score(y_true=all_trues, y_pred=all_preds)\n",
    "        precision = precision_score(y_true=all_trues, y_pred=all_preds, zero_division=0, average=avg)\n",
    "        recall = recall_score(y_true=all_trues, y_pred=all_preds, zero_division=0, average=avg)\n",
    "        f1 = f1_score(y_true=all_trues, y_pred=all_preds, zero_division=0, average=avg)\n",
    "\n",
    "        avg_eval_loss = eval_loss / (len(val_loader))\n",
    "\n",
    "        metrics = {\n",
    "            'accuracy': acc_total, \n",
    "            'precision': precision, \n",
    "            'recall': recall, \n",
    "            'f1': f1, \n",
    "            'avg_eval_loss': avg_eval_loss\n",
    "        }\n",
    "        wandb.log(metrics)\n",
    "        print('****Evaluation****')\n",
    "        print(f'total_accuracy: {acc_total}')\n",
    "\n",
    "        return acc_total\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(model, num_epochs, run_name, lr, architecture, frozen_layers, dataset='CrisisMMD'):\n",
    "    # training hyperparameters & functions/tools\n",
    "    lr = lr \n",
    "    num_epochs = num_epochs\n",
    "    run_name = run_name\n",
    "    \n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) #stocastic gradient descent for our optimization algorithm\n",
    "    lr_sched = MultiStepLR(optimizer=optimizer, milestones=list(range(50, num_epochs, 30)), gamma=.1)\n",
    "\n",
    "    model.to(device)\n",
    "    # for saving the models\n",
    "    Path(research_dir, 'models' ).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # before training, set up wandb for tracking purposes\n",
    "    os.environ[\"WANDB_API_KEY\"] = \"5a08d1ebbf0e86ab877a128b98be3c320301b6a0\"\n",
    "\n",
    "    run = wandb.init(\n",
    "        # Set the wandb entity where your project will be logged (generally your team name).\n",
    "        entity=\"agafiabschool-stephen-f-austin-state-university\",\n",
    "        # Set the wandb project where this run will be logged.\n",
    "        project=\"Research Project for CSCI-1465\",\n",
    "        # Track hyperparameters and run metadata.\n",
    "        config={\n",
    "            \"learning_rate\": lr,\n",
    "            \"architecture\": architecture,\n",
    "            \"dataset\": dataset,\n",
    "            \"epochs\": num_epochs,\n",
    "            'frozen_layers': frozen_layers,\n",
    "        }, name=run_name\n",
    "    )\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        wandb.log({'epoch': epoch+1})\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for b, batch in tqdm.tqdm(enumerate(train_loader), \n",
    "                            total= len(train_loader), desc=f\"Processing training data in epoch {epoch+1}\"):\n",
    "            model.train()\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            model.zero_grad() \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            raw_logits = model.forward(images)\n",
    "            # loss - can use raw logits for this function b/c it applies LogSoftmax \n",
    "\n",
    "            class_weights = torch.tensor([1.0, 1.5]).to(device)\n",
    "            loss = nn.CrossEntropyLoss(weight=class_weights)(raw_logits, labels)\n",
    "            print(f'Train Loss: {loss}')\n",
    "            wandb.log({'Train Loss': loss.item()})\n",
    "            wandb.log({'LR': lr_sched.get_last_lr()[0]})\n",
    "\n",
    "\n",
    "            # backprop!\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if (b+1) % 20 == 0:\n",
    "                print(f'batch: {b+1} ; loss: {loss.item()}')\n",
    "        \n",
    "        # each epoch, run validation\n",
    "        acc = dev(model=model, val_loader=val_loader)\n",
    "        \n",
    "        if acc > best_val_acc:\n",
    "            best_val_acc = acc\n",
    "            torch.save(model, Path(research_dir, 'models', f'{run_name}'))\n",
    "        \n",
    "        lr_sched.step()\n",
    "    \n",
    "    return best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38971e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to train\n",
    "num_epochs = 200\n",
    "os.chdir(home)\n",
    "\n",
    "# for grid-search\n",
    "history = []\n",
    "# for lr in [10**-4, 30**-4, 10**-3, 30**-3, 10**-2, 30**-2, 10**-1, 30**-1, 1]:\n",
    "for lr in [10**-2, 10**-1, 30**-1, 1]:\n",
    "    # run_name = f'MobileNetV2 lr={lr}'\n",
    "    run_name = f'MobileNetV2-extra fc - class_weights - 6 layers frozen - lr={lr}'\n",
    "    my_dict = {}\n",
    "    my_dict['lr'] = lr\n",
    "\n",
    "    # instantiate our model\n",
    "    model = MobileNetV2()\n",
    "    \n",
    "\n",
    "    # load pretrained weights\n",
    "    pretrained = mobilenet_v2(weights='IMAGENET1K_V2')\n",
    "    weights = pretrained.state_dict()\n",
    "    model.features.load_state_dict(weights, strict=False)\n",
    "\n",
    "    # turn off all but the topmost layers\n",
    "    freeze_up_to = 9\n",
    "    for param in model.features[:freeze_up_to].parameters(): \n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model = nn.Sequential(model, nn.Linear(1280, 512), nn.ReLU(), nn.Linear(512, 128), nn.ReLU(), nn.Linear(128, 2)) # 1280 is the num of features outputted by MobileNetv2 after flattening\n",
    "    \n",
    "    acc = train_eval(model, num_epochs, run_name, lr=lr, architecture='MobileNetV2', frozen_layers=freeze_up_to, dataset='CrisisMMD - Hurricane Images')\n",
    "    my_dict['acc'] = acc\n",
    "    history.append(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3eba19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
